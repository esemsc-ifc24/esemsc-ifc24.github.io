<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Imperial Mech Interp (IMI) - AI Safety Research Group</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<header>
    <h1>Imperial Mechanistic Interpretability</h1>
    <p>AI safety research group at Imperial College London</p>
    <!--<nav>
        <ul>
            <li><a href="#about">About Us</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#team">Team</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>-->
</header>

<main>
    <div id="content">
        <section id="about">
            <h2>About Us</h2>
            <p>Welcome to IMI, the student-run Imperial College London AI Safety research group, focused on mechanistic interpretability!  Our team has several projects running with the aim to explore comprehensively how AI systems work, from individual neurons to complex circuits. We want to contribute to reaching transparent and reliable AI developments.</p>
        </section>

        <section id="research">
            <h2>Research Interests</h2>

            <p>We started with fundamental mechanistic interpretability techniques and are diving into exciting research. Currently, we focus on:
            <ul>
                <li><strong>Circuit Detection:</strong> Mapping connections in neural networks to understand specific pathways and circuits, getting insights into the roles of individual neurons.</li>
                <li><strong>Neuron and Layer Functionality Mapping:</strong> Developing tools to identify and categorize neuron and layer functions, aiming to build a comprehensive view of how information is represented and processed at different layers within the model.</li>
                <li><strong>Core Mechanistic Interpretability Studies:</strong> Our main projects currently include denoising diffusion models, understanding feature interactions between layers, and studying sparse feature circuits in large language models for specific refusal mechanisms.</li>
            </ul>
        </section>
    </div>

    <aside id="side-info">
        <div id="team">
            <h2>Our Team</h2>
            <h3>Lab Members:</h3>
            <p><a href="https://idacy.github.io/" target="_blank">Ida Caspary</a> â€“ Head</p>
            <p><a href="https://github.com/esemsc-ak2822">Anirudh Krishnan</a></p>
            <p><a href="https://github.com/gems-oce23">Cynthia</a> </p>
            <p><a href="https://github.com/esemsc-jc1424">Finley</a> </p>
            <p><a href="https://github.com/esemsc-hyb24">Hazem Bakhashwain</a></p>
            <p><a href="https://github.com/esemsc-ims24">Mayowa</a></p>
            <p><a href="https://github.com/esemsc-pkw21">Prince Wihioka</a></p>
            <p>Shaily Desai</p>
            <p><a href="https://github.com/esemsc-ss2524">Simranjeet Singh</a></p>
            <p><a href="https://github.com/esemsc-ssa221">Sukhmit Singh</a></p>
            <p>Yiding</p>
            <p><a href="https://github.com/esemsc-zl1924">Zenith Liu</a></p>
        </div>

        <div id="contact">
            <h2>Contact</h2>
            <p>ida.caspary24[at]<br>
                imperial.ac.uk</p>
        </div>
    </aside>
</main>

<footer>
    <p>&copy; 2024 IMI</p>
</footer>

</body>
</html>
